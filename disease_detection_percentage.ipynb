{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train Disease Percentage Prediction Model\n",
        "Optimized version using kagglehub and tf.data pipeline\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import kagglehub\n",
        "import json\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
        "DATA_DIR = os.path.join(path, \"PlantVillage\")\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 25\n",
        "\n",
        "# Focus on common farmer crops\n",
        "FARMER_CROPS = [\"Tomato\", \"Potato\", \"Apple\", \"Corn\", \"Grape\", \"Strawberry\", \"Pepper\", \"Soybean\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Step 1: Collect image paths and labels\n",
        "# -----------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"Disease Percentage Model Training\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Filter classes to farmer-relevant crops\n",
        "classes = [cls for cls in sorted(os.listdir(DATA_DIR))\n",
        "           if any(crop.lower() in cls.lower() for crop in FARMER_CROPS)]\n",
        "\n",
        "print(f\"\\nFound {len(classes)} relevant crop disease classes\")\n",
        "\n",
        "# Create disease percentage mapping\n",
        "disease_mapping = {}\n",
        "for cls in classes:\n",
        "    if \"healthy\" in cls.lower():\n",
        "        disease_mapping[cls] = 0.0\n",
        "    elif \"early\" in cls.lower() or \"spot\" in cls.lower():\n",
        "        disease_mapping[cls] = 0.2\n",
        "    elif \"late\" in cls.lower() or \"severe\" in cls.lower():\n",
        "        disease_mapping[cls] = 0.8\n",
        "    else:\n",
        "        disease_mapping[cls] = 0.5\n",
        "\n",
        "# Save mapping\n",
        "with open('disease_mapping.json', 'w') as f:\n",
        "    json.dump(disease_mapping, f, indent=2)\n",
        "print(\"Disease mapping saved\")\n",
        "\n",
        "# Collect image paths and labels\n",
        "for cls_name in classes:\n",
        "    cls_path = os.path.join(DATA_DIR, cls_name)\n",
        "    img_files = [f for f in os.listdir(cls_path)\n",
        "                 if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))][:400]  # Limit per class\n",
        "\n",
        "    print(f\"Loading {len(img_files)} images from {cls_name}\")\n",
        "\n",
        "    for f in img_files:\n",
        "        image_paths.append(os.path.join(cls_path, f))\n",
        "        # Add slight variation to disease percentage\n",
        "        labels.append(disease_mapping[cls_name] + np.random.uniform(-0.05, 0.05))\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.clip(np.array(labels, dtype=np.float32), 0.0, 1.0)\n",
        "\n",
        "print(f\"\\nTotal images collected: {len(image_paths)}\")\n",
        "print(f\"Label distribution - Min: {labels.min():.3f}, Max: {labels.max():.3f}, Mean: {labels.mean():.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Step 2: Create tf.data.Dataset\n",
        "# -----------------------------\n",
        "print(\"\\nCreating tf.data pipeline...\")\n",
        "\n",
        "def process_image(file_path, label):\n",
        "    \"\"\"Efficient image processing pipeline\"\"\"\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Create dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "dataset = dataset.shuffle(buffer_size=len(labels), seed=42)\n",
        "dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Split into train and validation\n",
        "val_size = int(0.2 * len(labels) / BATCH_SIZE)\n",
        "train_ds = dataset.skip(val_size)\n",
        "val_ds = dataset.take(val_size)\n",
        "\n",
        "print(f\"Training batches: {tf.data.experimental.cardinality(train_ds).numpy()}\")\n",
        "print(f\"Validation batches: {tf.data.experimental.cardinality(val_ds).numpy()}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Step 3: Model Definition with Data Augmentation\n",
        "# -----------------------------\n",
        "print(\"\\nBuilding model...\")\n",
        "\n",
        "# Data augmentation for better generalization\n",
        "data_aug = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.15),\n",
        "    layers.RandomContrast(0.1)\n",
        "])\n",
        "\n",
        "# Base model with fine-tuning\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "\n",
        "# Unfreeze last 150 layers for fine-tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-150]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build complete model\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_aug(inputs)\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "x = base_model(x, training=True)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile with Huber loss (robust to outliers)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=tf.keras.losses.Huber(),\n",
        "    metrics=[\"mae\", \"mse\"]\n",
        ")\n",
        "\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# -----------------------------\n",
        "# Step 4: Training\n",
        "# -----------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting Training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        'disease_percentage_model_best.h5',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Step 5: Evaluation and Save\n",
        "# -----------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training Complete! Evaluating...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Final evaluation\n",
        "results = model.evaluate(val_ds, verbose=0)\n",
        "print(f\"\\nFinal Validation Results:\")\n",
        "print(f\"  Loss: {results[0]:.4f}\")\n",
        "print(f\"  MAE: {results[1]:.4f}\")\n",
        "print(f\"  MSE: {results[2]:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(results[2]):.4f}\")\n",
        "\n",
        "# Sample predictions\n",
        "print(\"\\nSample Predictions:\")\n",
        "sample_batch = next(iter(val_ds))\n",
        "sample_preds = model.predict(sample_batch[0][:5], verbose=0)\n",
        "sample_actuals = sample_batch[1][:5].numpy()\n",
        "\n",
        "for i, (pred, actual) in enumerate(zip(sample_preds, sample_actuals)):\n",
        "    error = abs(pred[0] - actual)\n",
        "    print(f\"  Sample {i+1}: Predicted={pred[0]:.3f}, Actual={actual:.3f}, Error={error:.3f}\")\n",
        "\n",
        "# Save complete pipeline\n",
        "import joblib\n",
        "joblib.dump((model, history.history), \"plant_disease_pipeline_final.pkl\", compress=3)\n",
        "model.save('disease_percentage_model.h5')\n",
        "\n",
        "print(\"\\n✅ Models saved successfully!\")\n",
        "print(\"  - plant_disease_pipeline_final.pkl (complete pipeline)\")\n",
        "print(\"  - disease_percentage_model.h5 (Keras model)\")\n",
        "print(\"  - disease_percentage_model_best.h5 (best checkpoint)\")\n",
        "print(\"  - disease_mapping.json (class mapping)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training Pipeline Complete!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "icxo9LPorTre",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21f93071-d88f-4cc4-fee1-1776d98f5790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'plantdisease' dataset.\n",
            "============================================================\n",
            "Disease Percentage Model Training\n",
            "============================================================\n",
            "\n",
            "Found 15 relevant crop disease classes\n",
            "Disease mapping saved\n",
            "Loading 400 images from Pepper__bell___Bacterial_spot\n",
            "Loading 400 images from Pepper__bell___healthy\n",
            "Loading 400 images from Potato___Early_blight\n",
            "Loading 400 images from Potato___Late_blight\n",
            "Loading 152 images from Potato___healthy\n",
            "Loading 400 images from Tomato_Bacterial_spot\n",
            "Loading 400 images from Tomato_Early_blight\n",
            "Loading 400 images from Tomato_Late_blight\n",
            "Loading 400 images from Tomato_Leaf_Mold\n",
            "Loading 400 images from Tomato_Septoria_leaf_spot\n",
            "Loading 400 images from Tomato_Spider_mites_Two_spotted_spider_mite\n",
            "Loading 400 images from Tomato__Target_Spot\n",
            "Loading 400 images from Tomato__Tomato_YellowLeaf__Curl_Virus\n",
            "Loading 373 images from Tomato__Tomato_mosaic_virus\n",
            "Loading 400 images from Tomato_healthy\n",
            "\n",
            "Total images collected: 5725\n",
            "Label distribution - Min: 0.000, Max: 0.850, Mean: 0.314\n",
            "\n",
            "Creating tf.data pipeline...\n",
            "Training batches: 287\n",
            "Validation batches: 71\n",
            "\n",
            "Building model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ true_divide (\u001b[38;5;33mTrueDivide\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ subtract (\u001b[38;5;33mSubtract\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ true_divide (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,618,945\u001b[0m (9.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,618,945</span> (9.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,583,905\u001b[0m (9.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,583,905</span> (9.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m35,040\u001b[0m (136.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,040</span> (136.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Starting Training...\n",
            "============================================================\n",
            "Epoch 1/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0315 - mae: 0.1952 - mse: 0.0629\n",
            "Epoch 1: val_loss improved from inf to 0.07048, saving model to disease_percentage_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 156ms/step - loss: 0.0314 - mae: 0.1951 - mse: 0.0629 - val_loss: 0.0705 - val_mae: 0.3388 - val_mse: 0.1410 - learning_rate: 1.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0180 - mae: 0.1428 - mse: 0.0359\n",
            "Epoch 2: val_loss improved from 0.07048 to 0.05192, saving model to disease_percentage_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 152ms/step - loss: 0.0180 - mae: 0.1428 - mse: 0.0359 - val_loss: 0.0519 - val_mae: 0.2868 - val_mse: 0.1038 - learning_rate: 1.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0143 - mae: 0.1263 - mse: 0.0286\n",
            "Epoch 3: val_loss improved from 0.05192 to 0.04728, saving model to disease_percentage_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 155ms/step - loss: 0.0143 - mae: 0.1263 - mse: 0.0286 - val_loss: 0.0473 - val_mae: 0.2707 - val_mse: 0.0946 - learning_rate: 1.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0135 - mae: 0.1186 - mse: 0.0269\n",
            "Epoch 4: val_loss improved from 0.04728 to 0.03214, saving model to disease_percentage_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 154ms/step - loss: 0.0134 - mae: 0.1186 - mse: 0.0269 - val_loss: 0.0321 - val_mae: 0.2258 - val_mse: 0.0643 - learning_rate: 1.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0104 - mae: 0.1014 - mse: 0.0208\n",
            "Epoch 5: val_loss improved from 0.03214 to 0.03190, saving model to disease_percentage_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 154ms/step - loss: 0.0104 - mae: 0.1014 - mse: 0.0208 - val_loss: 0.0319 - val_mae: 0.2130 - val_mse: 0.0638 - learning_rate: 1.0000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0076 - mae: 0.0855 - mse: 0.0152\n",
            "Epoch 6: val_loss did not improve from 0.03190\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 153ms/step - loss: 0.0076 - mae: 0.0855 - mse: 0.0152 - val_loss: 0.0555 - val_mae: 0.2434 - val_mse: 0.1110 - learning_rate: 1.0000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0072 - mae: 0.0828 - mse: 0.0144\n",
            "Epoch 7: val_loss improved from 0.03190 to 0.03149, saving model to disease_percentage_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 154ms/step - loss: 0.0072 - mae: 0.0828 - mse: 0.0144 - val_loss: 0.0315 - val_mae: 0.2231 - val_mse: 0.0630 - learning_rate: 1.0000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0069 - mae: 0.0792 - mse: 0.0139\n",
            "Epoch 8: val_loss did not improve from 0.03149\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 153ms/step - loss: 0.0069 - mae: 0.0792 - mse: 0.0139 - val_loss: 0.0475 - val_mae: 0.2746 - val_mse: 0.0950 - learning_rate: 1.0000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0065 - mae: 0.0752 - mse: 0.0129\n",
            "Epoch 9: val_loss did not improve from 0.03149\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 151ms/step - loss: 0.0065 - mae: 0.0752 - mse: 0.0129 - val_loss: 0.0536 - val_mae: 0.2918 - val_mse: 0.1071 - learning_rate: 1.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0059 - mae: 0.0703 - mse: 0.0117\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.03149\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 152ms/step - loss: 0.0059 - mae: 0.0703 - mse: 0.0117 - val_loss: 0.0518 - val_mae: 0.2840 - val_mse: 0.1036 - learning_rate: 1.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0044 - mae: 0.0640 - mse: 0.0088\n",
            "Epoch 11: val_loss did not improve from 0.03149\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 152ms/step - loss: 0.0044 - mae: 0.0640 - mse: 0.0088 - val_loss: 0.0424 - val_mae: 0.2608 - val_mse: 0.0848 - learning_rate: 5.0000e-05\n",
            "Epoch 12/25\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0044 - mae: 0.0607 - mse: 0.0088\n",
            "Epoch 12: val_loss did not improve from 0.03149\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 151ms/step - loss: 0.0044 - mae: 0.0607 - mse: 0.0088 - val_loss: 0.0403 - val_mae: 0.2521 - val_mse: 0.0806 - learning_rate: 5.0000e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\n",
            "============================================================\n",
            "Training Complete! Evaluating...\n",
            "============================================================\n",
            "\n",
            "Final Validation Results:\n",
            "  Loss: 0.0334\n",
            "  MAE: 0.2309\n",
            "  MSE: 0.0667\n",
            "  RMSE: 0.2583\n",
            "\n",
            "Sample Predictions:\n",
            "  Sample 1: Predicted=0.396, Actual=0.186, Error=0.210\n",
            "  Sample 2: Predicted=0.387, Actual=0.243, Error=0.144\n",
            "  Sample 3: Predicted=0.326, Actual=0.838, Error=0.512\n",
            "  Sample 4: Predicted=0.391, Actual=0.788, Error=0.396\n",
            "  Sample 5: Predicted=0.334, Actual=0.201, Error=0.133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Models saved successfully!\n",
            "  - plant_disease_pipeline_final.pkl (complete pipeline)\n",
            "  - disease_percentage_model.h5 (Keras model)\n",
            "  - disease_percentage_model_best.h5 (best checkpoint)\n",
            "  - disease_mapping.json (class mapping)\n",
            "\n",
            "============================================================\n",
            "Training Pipeline Complete!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}